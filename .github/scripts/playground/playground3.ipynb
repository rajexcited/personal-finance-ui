{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_path = \"regression_test_plan.md\"\n",
    "with open(regression_path, \"r\") as f:\n",
    "    regression_template_lines = f.readlines()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import List\n",
    "\n",
    "def parse_metadata(lines:List[str]):\n",
    "    metadata = None\n",
    "\n",
    "    for line_num, line in enumerate(lines):\n",
    "        if line.strip() == \"---\":\n",
    "            if metadata == None:\n",
    "                metadata = dict()\n",
    "            else:\n",
    "                return metadata, line_num\n",
    "        else:\n",
    "            metadata_match = re.match(r\"(.+):(.+)\", line)\n",
    "            if metadata_match:\n",
    "                key = metadata_match.group(1).strip()\n",
    "                text = metadata_match.group(2).strip()\n",
    "                if key in metadata:\n",
    "                    raise ValueError(\"duplicate metadata key\")\n",
    "                metadata[key] = text\n",
    "\n",
    "print(parse_metadata(regression_template_lines))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md,ln=parse_metadata(regression_template_lines)\n",
    "print(md)\n",
    "print(ln)\n",
    "print(regression_template_lines[ln+1:])\n",
    "\n",
    "def is_new_line(line):\n",
    "    return line.strip() == \"\"\n",
    "\n",
    "print(is_new_line(regression_template_lines[ln]))\n",
    "print(is_new_line(regression_template_lines[ln+1]))\n",
    "print(is_new_line(regression_template_lines[ln+2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "def is_table(line):\n",
    "    return re.match(r\"\\|.*\\|\", line)\n",
    "\n",
    "def is_heading(line):\n",
    "    return re.match(r\"^(#+) (.+)\", line)\n",
    "\n",
    "# list_match = re.match(r\"^[-*+] (.+)\", line)\n",
    "\n",
    "def parse_regression_template(lines):\n",
    "    metadata, line_num = parse_metadata(lines)\n",
    "    if metadata == None:\n",
    "        raise ValueError(\"metadata not found\")\n",
    "    \n",
    "    result = {\n",
    "        \"metadata\": metadata,\n",
    "        \"content\": {}\n",
    "    }\n",
    "    \n",
    "    heading_dict = None\n",
    "    for line_num, line in enumerate(lines[line_num+1:]):\n",
    "\n",
    "        heading_match = is_heading(line)\n",
    "        # print(heading_match)\n",
    "        if heading_match:\n",
    "            hlevel = len(heading_match.group(1))  # Number of `#`\n",
    "            htitle = heading_match.group(2).strip()\n",
    "            heading_dict = result[\"content\"][line_num] = {\"headingLevel\": hlevel, \"headingTitle\": htitle, \"content\": []}\n",
    "\n",
    "        if not heading_dict:\n",
    "            if len(line.strip()) == 0:\n",
    "                continue\n",
    "            heading_dict = result[\"content\"][line_num] = {\"headingLevel\": 0, \"headingTitle\": \"\", \"content\": []}\n",
    "\n",
    "        heading_dict[\"content\"].append(line.strip())\n",
    "    \n",
    "    return result\n",
    "  \n",
    " \n",
    "parsed = parse_regression_template(regression_template_lines)\n",
    "\n",
    "print(json.dumps(parsed, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in parsed template, we have metadata and content\n",
    "# content dictionary has key as line number.\n",
    "# there is content array in value which is useful to format template in markdown\n",
    "# we can use this to generate test plan in markdown format\n",
    "# content array has variables usage in the template denoting $variable_name\n",
    "# only table of test scenario is special. we will need to add rows to the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# step1: call convert tc and summary methods to get list of test cases\n",
    "# python .\\.github\\scripts\\parse_test_cases.py --convert --tc-dir test-cases\\ --converted-filename playground3-converted-tcs\n",
    "with open(\"../../../dist/playground3-converted-tcs.json\", \"r\") as f:\n",
    "    converted_tcs = json.load(f)\n",
    "\n",
    "# step2: generate summary for type of test cases\n",
    "# python .\\.github\\scripts\\summary_tc.py --analyze --converted-tc-path dist\\playground3-converted-tcs.json --summary-filename playground3-summary-typeoftest --key-path \"details.Type of Test\"\n",
    "\n",
    "with open(\"../../../dist/playground3-summary-typeoftest.json\", \"r\") as f:\n",
    "    summary_typeoftest = json.load(f)\n",
    "\n",
    "regression_testcases = summary_typeoftest[\"Regression\"]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "from typing import List, Dict\n",
    "\n",
    "def group_list_into_map(items: List[str]) -> Dict[str, List[str]]:\n",
    "    keyword_count = Counter()\n",
    "    keyword_map = defaultdict(set)\n",
    "\n",
    "    exclude_keywords = [ \"api\", \"form\", \"add\", \"page\" ]\n",
    "    # Count occurrences of each keyword\n",
    "    for item in items:\n",
    "        keywords = item.split()\n",
    "        for keyword in keywords:\n",
    "            if keyword in exclude_keywords:\n",
    "                continue\n",
    "            keyword_count[keyword] += 1\n",
    "            keyword_map[keyword].add(item)\n",
    "\n",
    "    # Sort keywords by their occurrences in descending order\n",
    "    sorted_keywords = sorted(keyword_count.keys(), key=lambda k: -keyword_count[k])\n",
    "\n",
    "    # Create the final map with unique values\n",
    "    final_map = {}\n",
    "    seen_items = set()\n",
    "\n",
    "    for keyword in sorted_keywords:\n",
    "        unique_items = [item for item in keyword_map[keyword] if item not in seen_items]\n",
    "        if unique_items:\n",
    "            final_map[keyword] = unique_items\n",
    "            seen_items.update(unique_items)\n",
    "\n",
    "    return final_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def get_variable_name(content):\n",
    "    return re.findall(r\"\\$[a-zA-Z0-9_\\.]+\", content)\n",
    "\n",
    "get_variable_name(\"This is $variable1 and $var.able.2\")\n",
    "\n",
    "def is_list(content):\n",
    "    return re.match(r\"^[-*+] (.+)\", content)\n",
    "\n",
    "\n",
    "def get_value(variable:str, tc_id:str=None):\n",
    "    testcases = regression_testcases if tc_id is None else [tc_id]\n",
    "    ia_list = set()\n",
    "    for tc in testcases:\n",
    "        if variable == \"$details.impact_area\":\n",
    "            for k,v in converted_tcs[tc][\"details\"][\"Impact Area\"].items():\n",
    "                ia_list.add(k)\n",
    "                for lv in v:\n",
    "                    ia_list.add(lv)\n",
    "        if variable == \"$details.tags.feature\":\n",
    "            ia_list.update([v for v in  converted_tcs[tc][\"details\"][\"Tags\"][\"feature\"]])\n",
    "        if variable == \"$details.tags.impact\":\n",
    "            ia_list.update([fv for fv in converted_tcs[tc][\"details\"][\"Tags\"][\"impact\"]])\n",
    "        if variable == \"$details.title\":\n",
    "            ia_list.add(converted_tcs[tc][\"details\"][\"Title\"])\n",
    "        if variable == \"$metadata.id\":\n",
    "            ia_list.add(converted_tcs[tc][\"metadata\"][\"id\"])\n",
    "        if variable == \"$metadata.relative_file_path\":\n",
    "            ia_list.add(converted_tcs[tc][\"metadata\"][\"relative_file_path\"].replace(\"\\\\\", \"/\"))\n",
    "    if len(ia_list) == 0:\n",
    "        return [variable]\n",
    "    return sorted(ia_list)\n",
    "\n",
    "def replace_variables(content_line:str, variables:List[str], tc_id:str=None):\n",
    "    content = \"\"\n",
    "    if is_list(content_line) and len(variables) == 1:\n",
    "        var = variables[0]\n",
    "        ll = get_value(var, tc_id)\n",
    "        gmap = group_list_into_map(ll)\n",
    "        clist = []\n",
    "        for gv in gmap.values():\n",
    "            clist.append(content_line.replace(var, \", \".join(gv)))\n",
    "        content = \"\\n\".join(clist)\n",
    "    else:\n",
    "        content = content_line\n",
    "        for var in variables:\n",
    "            ll = get_value(var, tc_id)\n",
    "            content = content.replace(var, \", \".join(ll))\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_milestone_details(milestone:str):\n",
    "    \n",
    "    return {\n",
    "        \"milestone\": milestone,\n",
    "        \"milestone_start\": \"2021-06-01\",\n",
    "        \"milestone_end\": \"2021-06-30\",\n",
    "        \"milestone_duration\": 30\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_line_numbers = sorted(parsed[\"content\"].keys())\n",
    "\n",
    "file_contents = []\n",
    "\n",
    "for line_num in sorted_line_numbers:\n",
    "    content = parsed[\"content\"][line_num][\"content\"]\n",
    "    variables_in_content = list()\n",
    "    \n",
    "    for content_line in content:\n",
    "        variables = get_variable_name(content_line)\n",
    "        variables_in_content.extend(variables)\n",
    "        if \"$ind\" in variables and parsed[\"content\"][line_num][\"headingTitle\"].startswith(\"Test Scenarios for Regression\"):\n",
    "            for ind, tc in enumerate(regression_testcases):\n",
    "                tc_content = content_line.replace(\"$ind\", str(ind+1))\n",
    "                file_contents.append(replace_variables(tc_content, variables, tc))\n",
    "        else:\n",
    "            file_contents.append(replace_variables(content_line, variables))\n",
    "\n",
    "    # print(variables_in_content)\n",
    "        # for variable in variables:\n",
    "        #     if variable not in parsed[\"metadata\"]:\n",
    "        #         print(f\"Variable {variable} not found in metadata\")\n",
    "        #     else:\n",
    "        #         content_line = content_line.replace(variable, parsed[\"metadata\"][variable])\n",
    "        # parsed[\"content\"][line_num][\"content\"] = content_line\n",
    "# print(file_contents)\n",
    "\n",
    "# print(\"\\n\".join(file_contents))\n",
    "\n",
    "with open(\"../../../dist/regression_test_plan_generated.md\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(file_contents))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "testplan_content = \"Regression Test Plan: [testplan issue-12](https://github.com/rajexcited/personal-finance-ui/issues/12)\"\n",
    "linkMatch = re.match(r\"([a-zA-Z]+) Test Plan:.+https.+/issues/(\\d+).*\",\n",
    "                         testplan_content, re.IGNORECASE)\n",
    "\n",
    "if linkMatch:\n",
    "    print(linkMatch.group(1))\n",
    "    print(linkMatch.group(2))\n",
    "else:\n",
    "    print(\"No match\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "request_form_path=Path(\"../../../../finance-journal-ui/dist/request_form_issue_details.json\")\n",
    "print(request_form_path.resolve(), request_form_path.exists())\n",
    "\n",
    "with open(request_form_path, \"r\") as rf:\n",
    "    request_form_json = json.load(rf)\n",
    "\n",
    "print(request_form_json[\"body\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from markdown_to_json import dictify\n",
    "body:str=request_form_json[\"body\"]\n",
    "lines=body.split(\"\\n\")\n",
    "lines.insert(1,\"## Dummy\")\n",
    "print(\"\\n\".join(lines))\n",
    "parsed=dictify(\"\\n\".join(lines))\n",
    "ignorek, request_dict_parsed=parsed.popitem()\n",
    "# type(request_dict_parsed)\n",
    "print(type(request_dict_parsed))\n",
    "print(len(request_dict_parsed))\n",
    "for k,v in request_dict_parsed.items():\n",
    "    print(k, type(v))\n",
    "    for kk,vv in v.items():\n",
    "        print(kk, type(vv), vv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ignorek)\n",
    "# print(body)\n",
    "ind=body.find(ignorek)\n",
    "# print(ind+len(ignorek))\n",
    "header1_end_ind=body.find(\"\\n\", ind+len(ignorek))\n",
    "print(\"header1 ends at: \", header1_end_ind)\n",
    "\n",
    "print(body[:header1_end_ind] + \"\\n## Dummy\" + body[header1_end_ind:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List,Dict\n",
    "\n",
    "def parsed_body(requestform_body: str, header1_dummy: bool = False, header2_dummy: bool = False) -> List:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        requestform_body (str):  request form issue body\n",
    "        header1_dummy and header2_dummy are used for internal to correct the body to parse in dictionary\n",
    "    Returns:\n",
    "        list of header3 types, parsed header3 could be of any of these types; list, dict or str.\n",
    "    \"\"\"\n",
    "    parsed_req_form = dictify(requestform_body)\n",
    "    if not isinstance(parsed_req_form, Dict) and not header1_dummy:\n",
    "        # add header1 and retry\n",
    "        return parsed_body(\"# Dummy\\n\"+requestform_body, header1_dummy=True)\n",
    "\n",
    "    incorrect_format_error_message = \"request form is not in correct format. Please follow template `Request  Regression - Provision/Deprovision Test Plan Environment`\"\n",
    "\n",
    "    if not isinstance(parsed_req_form, Dict) or len(parsed_req_form) != 1:\n",
    "        raise TypeError(incorrect_format_error_message)\n",
    "\n",
    "    ignorek, header1_value = parsed_req_form.popitem()\n",
    "    if not isinstance(header1_value, Dict) and not header2_dummy:\n",
    "        # add header2 and retry\n",
    "        header1_index = requestform_body.find(ignorek)\n",
    "        header1_end_index = requestform_body.find(\n",
    "            \"\\n\", header1_index+len(ignorek))\n",
    "        return parsed_body(requestform_body[:header1_end_index] + \"\\n## Dummy\" + requestform_body[header1_end_index:], header2_dummy=True)\n",
    "\n",
    "    if not isinstance(header1_value, Dict) or len(header1_value) != 1:\n",
    "        raise TypeError(incorrect_format_error_message)\n",
    "\n",
    "    ignorek, header2_value = header1_value.popitem()\n",
    "    if not isinstance(header2_value, Dict):\n",
    "        print(type(header2_value), header2_value)\n",
    "        raise TypeError(incorrect_format_error_message)\n",
    "\n",
    "    return header2_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(parsed_body(body))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
